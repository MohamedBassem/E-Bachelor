\chapter{Architecture}

As mentioned in the background section, one of the problems is that if there is a static dataset and multiple queries needs to be answered against this set, the whole dataset should be re-parsed with each query. The problem here is that there is no persistence. Each job runs separately from the other one. If we mange to keep the parsed set in the memory for other jobs to use, it will solve most of the problems.

To solve this problem, The concept of sessions should be introduced. Each session contains a previously parsed axiom set --- for example --- and in the session you can query this dataset multiple times. To handle all of those sessions a server is needed, so we decided to go with the server-client architecture to solve this problem. In the server-client architecture, there are one or more servers. Clients connect to these servers and have their own separate sessions.

\section{Server-Client Architecture}
\subsection{Server Design}
The deduction server is written in C and integrated with E but runs as a separate executable. The server starts by listening to a certain port for incoming \ac{tcp} connections. Whenever a client tries to connect to the server on that port a process is forked from the main process to serve the client. The server can handle many connections at the same time and each client is completely isolated from other clients connected to the server.

The client can then start interacting with the server using a pre-defined protocol. Using the protocol the client can upload axiom sets, remove them and query the server for proofs. Whenever the client uploads some set of axioms, the server parses, indexes and stores those axioms into its memory.

After the client chooses some axiom sets to be used in the proof search, he can start querying the server. The query consists of some optional additional axioms that will be discarded when the job finishes, and a conjecture. The server adds the new axioms to the knowledge base and passes the whole dataset to an E instance to solve the problem. The architecture is shown in Figure~\ref{fig:TheDeductionServerWithoutPruneAndStage}.

\includefig{0.82}{TheDeductionServerWithoutPruneAndStage.png}{Server Architecture}{fig:TheDeductionServerWithoutPruneAndStage}

One more feature that is added to server, is the ability to choose which axiom sets to consider in your proof. This feature is called staging. You could have many axiom sets in the server's memory, but only those who are staged will be considered when finding a proof. Consequently the server can be used as a pre-indexed, ready-to-use library of knowledge bases. The server also offers pre-uploaded sets of axioms that the client can use directly. This architecture is shown in Figure~\ref{fig:TheDeductionServerWithoutPrune}.

\includefig{0.82}{TheDeductionServerWithoutPrune.png}{Server Architecture with Staging}{fig:TheDeductionServerWithoutPrune}

\subsection{Client Design}
The E distribution comes also with a python client called ``enetcat.py'' which can be used to interact with the server. The python client is meant to be a reference implementation so that it can be ported into other languages. The client takes the address and the port of the deduction server as arguments and starts a \ac{tcp} connection to that port. The python client reads the user's commands from ``stdin'' and prints the output back to ``stdout''.

The client has two main parts that differentiates it from a normal telnet session. The first one is that the \ac{tcp} messages exchanged between the server and the client are encoded in a certain format. It is the python client's responsibility to encode outgoing messages into this format and decode incoming messages from this format. Usually, axiom set files include other axiom set files within them. The client expands those includes recursively into their content, so that the server receives axiom sets free of includes.

Having different implementations of the client in different programming languages makes it easier for complex systems to integrate with automated theorem provers and use them as a service. By just including the library, those systems do not need to have the ATP installed on their machines and do not need to care about the memory or the computation power needed for the proofs as proving conjectures is the server's responsibility.

\section{Pruning}
As mentioned before, the server can be used as a pre-indexed ready-to-use library of axioms. But this does not do any good to the proof search, thousand and even millions of axioms can be in the server's memory at any time. Answering a query with those axioms staged in the memory will yield a very large search space even if the query only needs a small subset of these axioms.

We need a component in our server that will select a subset of the axioms in the memory that are most probably relevant in the proof of this query. This process is called pruning. The new component will run on the knowledge base given the conjecture to filter irrelevant axioms and passing the resulted filtered axioms to the E prover to find the proof as shown in figure~\ref{fig:Pruning}.

\includefig{0.82}{Pruner.png}{Pruning}{fig:Pruning}

Currently the server supports only pruning by SinE. SinE works by calculating the frequency count of symbols in the axioms and then running the pruning algorithm. This works nicely with the server as staging and unstaging axioms is as easy as adding their frequency counts to the frequency table and removing them respectively.

The pruner produces smaller problems that is then passed to E. This architecture works, but is not fully utilizing the server's resources. Instead of trying to solve one problem, the pruner can be run with different parameters to get several different smaller problems. Each one of those problems is passed to E instances running in parallel. Whenever an E instance finds a solution to one of the problems, all the other instances are killed and the solution is returned back to the user. So the final server structure is the one shown in figure~\ref{fig:TheFinalDeductionServer}.

\includefig{0.82}{TheDeductionServer.png}{The Final Deduction Server Architecture}{fig:TheFinalDeductionServer}

\section{Communication}
\subsection{TCP Communication}\label{subsec:tcpCommunication}
The communication with the server is done over \ac{tcp} to ensure reliability. The session is created by initiating a \ac{tcp} connection with the server on a certain port. The session lives as long as the \ac{tcp} connection is open. A child process from the server is forked to serve this client. Protocol commands are a series of \ac{tcp} messages that follow a certain format. Each line should be in a separate \ac{tcp} message and must be encoded in the following format:

As an example, to send the message ``LIST\textbackslash{}n'' the raw \ac{tcp} message would be:
\begin{lstlisting}
  \x00\x00\x00\x09 \x4c\x49\x53\x54\x0a
\end{lstlisting}
The first four bytes \lstinline{\x00\x00\x00\x09} encode the length of the message which is 9 bytes. Then the remaining five bytes follow \lstinline{\x4c\x49\x53\x54\x0a} which contain actual content of the message. Sticking to the protocol new lines are important to the server and each line should be terminated with a new line. Server responses are encoded in the same way.

\subsection{Interaction Protocol}\label{subsec:interactionProtocol}
As mentioned before, the communication between the server and the client is in the form of commands and responses. The formal documentation of the protocol is in the appendix. Solving the problem mentioned in section~\ref{sec:eprover} will be used as an example to describe the protocol:
\lstinputlisting[numbers=left]{codes/protocolexample1.txt}
First of all, the axioms need to be uploaded to the server. This can be done using the ``ADD \ldots GO'' block. Axioms uploaded are parsed and stored in the memory of the server but do not get used into any proof yet. The server responds with the result of the execution after each command.
\lstinputlisting[numbers=left]{codes/protocolexample2.txt}
To start using the uploaded axioms in proofs, they need to be ``STAGE''d. If at any time the status of the session needs to be checked, the ``LIST'' command is used. LIST prints the axioms that are currently in the memory and whether they are staged or not in addition to server-side axiom sets. Server-side axiom sets can also be loaded into the server's memory using the ``LOAD'' command.
\lstinputlisting[numbers=left]{codes/protocolexample3.txt}
Now after staging the needed axioms, the ``RUN \ldots GO'' block can be used to start running the job. Axioms introduced in the RUN command block are used temporarily in this job and then discarded after the termination of the job.
\lstinputlisting[numbers=left]{codes/protocolexample4.txt}
Axiom sets can also be ``UNSTAGE''d or ``REMOVE''d completely from the system. Since sessions can be running for long time, the content of any axiom set can be checked using the ``DOWNLOAD'' command. In the last set of commands one of the axiom sets is removed the job is restarted. We will notice that a proof will not be found. Notice that the second job run did not need to state anything about the axioms to be used in the proof, they are already staged and ready-to-use in the server's memory.
